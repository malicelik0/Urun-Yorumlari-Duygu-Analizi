{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "125a6d46-b1ac-45f7-9d3f-5a4da5474918",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a364243-6317-4264-bf54-91e20ae91a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=pd.read_excel(\"removed3.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fcabbf8-a5d2-4298-b722-97ccaec3e4a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13079, 2)\n"
     ]
    }
   ],
   "source": [
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b2bffe3-ead8-457d-88e9-56e3b91431ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = a['rating'].value_counts().sort_index().plot(kind='bar', title='Rating Sayisi', figsize=(10, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da606626-a59d-4707-b311-f62066d665a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I loved the phone Thanks\n"
     ]
    }
   ],
   "source": [
    "example = a['Reviews'][51]\n",
    "print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61954939-9c01-4036-b5d7-e757a0ca4d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\malic\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57ca365b-c63d-4ed5-b355-06eb3ab2dbcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'loved', 'the', 'phone', 'Thanks']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = nltk.word_tokenize(example)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78b5e7c1-6b10-470d-9194-37f26d61b610",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\malic\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "147a0249-9abf-4a16-a063-866226d2e9c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 'PRP'),\n",
       " ('loved', 'VBD'),\n",
       " ('the', 'DT'),\n",
       " ('phone', 'NN'),\n",
       " ('Thanks', 'NNS')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged = nltk.pos_tag(tokens)\n",
    "tagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94e63423-b7e5-4b97-b2a7-915f85a0bd48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\malic\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\malic\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "016b6eb0-c9b2-4a81-8a8e-04bda6b28219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S I/PRP loved/VBD the/DT phone/NN Thanks/NNS)\n"
     ]
    }
   ],
   "source": [
    "entities = nltk.chunk.ne_chunk(tagged)\n",
    "entities.pprint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3fa4aba-956c-4db5-af4a-e6615774ed4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\malic\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0fbdaf0-b0c2-4c0d-b9de-f11ae72e29a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "sia = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e758322-da54-4d99-9725-452b91b07518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 0.318, 'pos': 0.682, 'compound': 0.6468}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sia.polarity_scores('I am so happy!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b58049aa-7dcd-4ebf-a510-dbc5c5720f17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.451, 'neu': 0.549, 'pos': 0.0, 'compound': -0.6249}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sia.polarity_scores('This is the worst thing ever.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aba90963-fc11-4344-b31c-8f2675be0052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 0.227, 'pos': 0.773, 'compound': 0.7783}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sia.polarity_scores(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bb5fa68c-d512-45b1-8547-a7450640f814",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.008999109268188477,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 29,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 13079,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac0cb1e3c70149beae3ff5406ef132f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13079 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res = {}\n",
    "for i, row in tqdm(a.iterrows(), total=len(a)):\n",
    "    text = row['Reviews']\n",
    "    rating = row['rating']\n",
    "    try:\n",
    "        res[i] = sia.polarity_scores(text)\n",
    "    except:    \n",
    "        i+1\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d280146a-994b-4996-a6f4-f0773703269d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vaders = pd.DataFrame(res).T\n",
    "vaders = vaders.reset_index().rename(columns={'index': 'rating'})\n",
    "vaders = vaders.merge(a, how='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c006415e-100c-4247-a373-3a59a09bf548",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "      <th>Reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Very high quality and beautiful Amazon is more...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>The product is really excellent although it re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Price is a very good choice in terms of perfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Thanks to Amazon Turkey before the product I g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>I got it very quickly It was very well preserv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>5</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>I just received phone today and finished setti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>5</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>So far I have only only used cell phones from ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>4</td>\n",
       "      <td>0.273</td>\n",
       "      <td>0.606</td>\n",
       "      <td>0.121</td>\n",
       "      <td>-0.4601</td>\n",
       "      <td>The only negative thing to point out is that s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>5</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Very fast phone for current standards Crazy an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>5</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>So far super satisfied with the cell phone Esp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     rating    neg    neu    pos  compound  \\\n",
       "0         5  0.000  1.000  0.000    0.0000   \n",
       "1         5  0.000  1.000  0.000    0.0000   \n",
       "2         5  0.000  1.000  0.000    0.0000   \n",
       "3         5  0.000  1.000  0.000    0.0000   \n",
       "4         5  0.000  1.000  0.000    0.0000   \n",
       "..      ...    ...    ...    ...       ...   \n",
       "245       5  0.000  1.000  0.000    0.0000   \n",
       "246       5  0.000  1.000  0.000    0.0000   \n",
       "247       4  0.273  0.606  0.121   -0.4601   \n",
       "248       5  0.000  1.000  0.000    0.0000   \n",
       "249       5  0.000  1.000  0.000    0.0000   \n",
       "\n",
       "                                               Reviews  \n",
       "0    Very high quality and beautiful Amazon is more...  \n",
       "1    The product is really excellent although it re...  \n",
       "2    Price is a very good choice in terms of perfor...  \n",
       "3    Thanks to Amazon Turkey before the product I g...  \n",
       "4    I got it very quickly It was very well preserv...  \n",
       "..                                                 ...  \n",
       "245  I just received phone today and finished setti...  \n",
       "246  So far I have only only used cell phones from ...  \n",
       "247  The only negative thing to point out is that s...  \n",
       "248  Very fast phone for current standards Crazy an...  \n",
       "249  So far super satisfied with the cell phone Esp...  \n",
       "\n",
       "[250 rows x 6 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vaders.head(250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c032fde3-686c-40a6-89d0-c1615b5698c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x300 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(12, 3))\n",
    "sns.barplot(data=vaders, x='rating', y='pos', ax=axs[0])\n",
    "sns.barplot(data=vaders, x='rating', y='neu', ax=axs[1])\n",
    "sns.barplot(data=vaders, x='rating', y='neg', ax=axs[2])\n",
    "axs[0].set_title('Positive')\n",
    "axs[1].set_title('Neutral')\n",
    "axs[2].set_title('Negative')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5e74cdef-2fa6-4521-8bff-ba75cbfce921",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "205db993-cb3c-4ded-a869-6ffb716f735d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.007000446319580078,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 29,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 747,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a34914523ad84ed494d22d1192502965",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/747 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.006997346878051758,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 29,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 898822,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "041ed653188d43148126bca8a6cf113c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.006009578704833984,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 29,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 456318,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5178873e8aa74b99a6319eb9a32dda4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.007002353668212891,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 29,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 150,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b9dafdf14514a72ab2f08a2824a79f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/150 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.00700688362121582,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 29,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 498679497,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f486a84289834d929abdfb1f908f8181",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\malic\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\_utils.py:146: UserWarning: Failed to initialize NumPy: module compiled against API version 0x10 but this version of numpy is 0xf (Triggered internally at ..\\torch\\csrc\\utils\\tensor_numpy.cpp:77.)\n",
      "  t = torch.tensor([], dtype=storage.dtype, device=storage.untyped().device)\n"
     ]
    }
   ],
   "source": [
    "MODEL = f\"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a5554887-2286-4ec5-a232-108225e3b5e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I loved the phone Thanks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 0.227, 'pos': 0.773, 'compound': 0.7783}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(example)\n",
    "sia.polarity_scores(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "155c82bb-d1d6-4e9b-aac1-500c25f24c38",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Numpy is not available",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m encoded_text \u001b[38;5;241m=\u001b[39m tokenizer(example, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m output \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mencoded_text)\n\u001b[1;32m----> 3\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[43moutput\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m scores \u001b[38;5;241m=\u001b[39m softmax(scores)\n\u001b[0;32m      5\u001b[0m scores_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroberta_neg\u001b[39m\u001b[38;5;124m'\u001b[39m : scores[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroberta_neu\u001b[39m\u001b[38;5;124m'\u001b[39m : scores[\u001b[38;5;241m1\u001b[39m],\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroberta_pos\u001b[39m\u001b[38;5;124m'\u001b[39m : scores[\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m      9\u001b[0m }\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Numpy is not available"
     ]
    }
   ],
   "source": [
    "encoded_text = tokenizer(example, return_tensors='pt')\n",
    "output = model(**encoded_text)\n",
    "scores = output[0][0].detach().numpy()\n",
    "scores = softmax(scores)\n",
    "scores_dict = {\n",
    "    'roberta_neg' : scores[0],\n",
    "    'roberta_neu' : scores[1],\n",
    "    'roberta_pos' : scores[2]\n",
    "}\n",
    "print(scores_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5383ab6b-9abb-4478-a554-61b0479e8ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def polarity_scores_roberta(example):\n",
    "    encoded_text = tokenizer(example, return_tensors='pt')\n",
    "    output = model(**encoded_text)\n",
    "    scores = output[0][0].detach().numpy()\n",
    "    scores = softmax(scores)\n",
    "    scores_dict = {\n",
    "        'roberta_neg' : scores[0],\n",
    "        'roberta_neu' : scores[1],\n",
    "        'roberta_pos' : scores[2]\n",
    "    }\n",
    "    return scores_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "97379f59-6cf8-43de-a8f5-33a6de64bd51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.006999492645263672,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 29,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 13079,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a003bca446824810b482e0040a691567",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13079 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Broke\n",
      "Broke\n",
      "Broke\n",
      "Broke\n",
      "Broke\n",
      "Broke\n",
      "Broke\n",
      "Broke\n",
      "Broke\n",
      "Broke\n",
      "Broke\n",
      "Broke\n",
      "Broke\n",
      "Broke\n",
      "Broke\n",
      "Broke\n",
      "Broke\n",
      "Broke\n",
      "Broke\n",
      "Broke\n",
      "Broke\n",
      "Broke\n",
      "Broke\n",
      "Broke\n",
      "Broke\n",
      "Broke\n",
      "Broke\n",
      "Broke\n",
      "Broke\n",
      "Broke\n",
      "Broke\n",
      "Broke\n",
      "Broke\n",
      "Broke\n",
      "Broke\n",
      "Broke\n",
      "Broke\n",
      "Broke\n",
      "Broke\n",
      "Broke\n",
      "Broke\n",
      "Broke\n",
      "Broke\n",
      "Broke\n",
      "Broke\n",
      "Broke\n",
      "Broke\n",
      "Broke\n",
      "Broke\n",
      "Broke\n",
      "Broke\n",
      "Broke\n",
      "Broke\n",
      "Broke\n",
      "Broke\n",
      "Broke\n",
      "Broke\n",
      "Broke\n",
      "Broke\n",
      "Broke\n",
      "Broke\n",
      "Broke\n",
      "Broke\n",
      "Broke\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m vader_result\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m      8\u001b[0m     vader_result_rename[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvader_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m value\n\u001b[1;32m----> 9\u001b[0m roberta_result \u001b[38;5;241m=\u001b[39m \u001b[43mpolarity_scores_roberta\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m both \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mvader_result_rename, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mroberta_result}\n\u001b[0;32m     11\u001b[0m res[i] \u001b[38;5;241m=\u001b[39m both\n",
      "Cell \u001b[1;32mIn[29], line 3\u001b[0m, in \u001b[0;36mpolarity_scores_roberta\u001b[1;34m(example)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpolarity_scores_roberta\u001b[39m(example):\n\u001b[0;32m      2\u001b[0m     encoded_text \u001b[38;5;241m=\u001b[39m tokenizer(example, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m     output \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mencoded_text)\n\u001b[0;32m      4\u001b[0m     scores \u001b[38;5;241m=\u001b[39m output[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m      5\u001b[0m     scores \u001b[38;5;241m=\u001b[39m softmax(scores)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:1215\u001b[0m, in \u001b[0;36mRobertaForSequenceClassification.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1207\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1208\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[0;32m   1209\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[0;32m   1210\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[0;32m   1211\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[0;32m   1212\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1213\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m-> 1215\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroberta\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1216\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1217\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1221\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1222\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1223\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1224\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1225\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1226\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1227\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier(sequence_output)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:853\u001b[0m, in \u001b[0;36mRobertaModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    844\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m    846\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[0;32m    847\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[0;32m    848\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    851\u001b[0m     past_key_values_length\u001b[38;5;241m=\u001b[39mpast_key_values_length,\n\u001b[0;32m    852\u001b[0m )\n\u001b[1;32m--> 853\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    854\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    855\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    856\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    857\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    858\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    859\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    860\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    861\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    863\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    864\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    865\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    866\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:527\u001b[0m, in \u001b[0;36mRobertaEncoder.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    518\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mcheckpoint\u001b[38;5;241m.\u001b[39mcheckpoint(\n\u001b[0;32m    519\u001b[0m         create_custom_forward(layer_module),\n\u001b[0;32m    520\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    524\u001b[0m         encoder_attention_mask,\n\u001b[0;32m    525\u001b[0m     )\n\u001b[0;32m    526\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 527\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    528\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    529\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    530\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    531\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    532\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    533\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    534\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    535\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    537\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:412\u001b[0m, in \u001b[0;36mRobertaLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    400\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m    401\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    402\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    409\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[0;32m    410\u001b[0m     \u001b[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[0;32m    411\u001b[0m     self_attn_past_key_value \u001b[38;5;241m=\u001b[39m past_key_value[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 412\u001b[0m     self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    415\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    416\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    417\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mself_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    418\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    419\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    421\u001b[0m     \u001b[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:339\u001b[0m, in \u001b[0;36mRobertaAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m    330\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    331\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    337\u001b[0m     output_attentions: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    338\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m--> 339\u001b[0m     self_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    340\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    341\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    342\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    343\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    344\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    345\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    346\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    348\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(self_outputs[\u001b[38;5;241m0\u001b[39m], hidden_states)\n\u001b[0;32m    349\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (attention_output,) \u001b[38;5;241m+\u001b[39m self_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:265\u001b[0m, in \u001b[0;36mRobertaSelfAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    262\u001b[0m     attention_scores \u001b[38;5;241m=\u001b[39m attention_scores \u001b[38;5;241m+\u001b[39m attention_mask\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# Normalize the attention scores to probabilities.\u001b[39;00m\n\u001b[1;32m--> 265\u001b[0m attention_probs \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattention_scores\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    267\u001b[0m \u001b[38;5;66;03m# This is actually dropping out entire tokens to attend to, which might\u001b[39;00m\n\u001b[0;32m    268\u001b[0m \u001b[38;5;66;03m# seem a bit unusual, but is taken from the original Transformer paper.\u001b[39;00m\n\u001b[0;32m    269\u001b[0m attention_probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(attention_probs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\functional.py:1811\u001b[0m, in \u001b[0;36msoftmax\u001b[1;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[0;32m   1807\u001b[0m         ret \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m-\u001b[39m\u001b[38;5;28minput\u001b[39m)\u001b[38;5;241m.\u001b[39msoftmax(dim, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m   1808\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\n\u001b[1;32m-> 1811\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msoftmax\u001b[39m(\u001b[38;5;28minput\u001b[39m: Tensor, dim: Optional[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, _stacklevel: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m, dtype: Optional[DType] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m   1812\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Applies a softmax function.\u001b[39;00m\n\u001b[0;32m   1813\u001b[0m \n\u001b[0;32m   1814\u001b[0m \u001b[38;5;124;03m    Softmax is defined as:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1834\u001b[0m \n\u001b[0;32m   1835\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   1836\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28minput\u001b[39m):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "res = {}\n",
    "for i, row in tqdm(a.iterrows(), total=len(a)):\n",
    "    try:\n",
    "        text = row['Reviews']\n",
    "        vader_result = sia.polarity_scores(text)\n",
    "        vader_result_rename = {}\n",
    "        for key, value in vader_result.items():\n",
    "            vader_result_rename[f\"vader_{key}\"] = value\n",
    "        roberta_result = polarity_scores_roberta(text)\n",
    "        both = {**vader_result_rename, **roberta_result}\n",
    "        res[i] = both\n",
    "    except RuntimeError:\n",
    "        print(f'Broke')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a45043-0508-4e9e-8121-57cc863ad541",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(res).T\n",
    "results_df = results_df.reset_index().rename(columns={'index': 'rating'})\n",
    "results_df = results_df.merge(df, how='right')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
